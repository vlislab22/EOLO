<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>EOLO</title>
    <meta name="author" content="Yuanhuiyi Lyu">
    <meta name="description" content="Project page of EOLO">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" type="image/png" href="eccv_logo.png">
    <!-- Format -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="../format/app.css">
    <link rel="stylesheet" href="../format/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="../format/app.js"></script>

  </head>

  <body style=“text-align: center;”>
    <div class="container" id="main">
        <div class="row">
            <h1 class="col-md-12 text-center">
                Chasing Day and Night: Towards Robust and Efficient All-Day Object Detection Guided by an Event Camera<br /> 
<!--                 <small>
                    
                </small> -->
            </h1>
        </div>
        
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
			<img src="./image/jiahang.png" height="80px"><br>
                        <a href="" >
                         Jiahang Cao
                        </a>
                        
                        <br /> MICS Thrust, HKUST(GZ)
                        <br /> &nbsp &nbsp

                    </li>

                    <li>
			<img src="./image/xu1.png" height="80px"><br>
			<a href="https://zhengxujosh.github.io/" >
                        Xu Zheng
                      </a>
                      <br /> AI Thrust, HKUST(GZ)
                      <br /> &nbsp &nbsp
                    </li>

                    <li>
			<img src="./image/huiyi1.png" height="80px"><br>
                        <a href="" >
                           Yuanhuiyi Lyu
                        </a>
                        <br /> AI Thrust, HKUST(GZ) 
			<br /> &nbsp &nbsp
                    </li>
		<li>
			<img src="./image/jiaxu.png" height="80px"><br>
                        <a href="" >
                           Jiaxu Wang
                        </a>
                        <br /> MICS Thrust, HKUST(GZ) 
			<br /> &nbsp &nbsp
                    </li>
		<li>
			<img src="./image/renjing.png" height="80px"><br>
                        <a href="" >
                           Renjing Xu
                        </a>
                        <br /> MICS Thrust, HKUST(GZ) 
			<br /> &nbsp &nbsp
                    </li>
                  
                    <li>
			    <img src="./image/linwang.jpg" height="80px"><br>
                        <a href="https://addisonwang2013.github.io/vlislab/linwang.html">
                           Addison Lin Wang
                        </a>
                        <br /> AI Thrust, HKUST(GZ) 
			    <br/> Dept. of CSE, HKUST 
                    </li>
                </ul>
            </div>
        </div>



        <!-- ##### Elements #####-->
        <div class="row">
                <div class="col-md-8 col-md-offset-2 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
			                <a href="">
                            <img src="./image/arxiv.png" height="100px"><br>
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>

                            <img src="./image/youtube_icon.jpg" height="100px"><br>
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/AndyCao1125/EOLO_2023">
                            <img src="./image/github_icon.jpg" height="100px"><br>
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>

                        <!-- <li>
                            
                            <img src="./image/colab_icon.jpg" height="100px"><br>
                                <h4><strong>Colab</strong></h4>
                            </a>
                        </li> -->
 

                        <li>
                            <a href="">
                            <img src="./image/slide_icon.jpg" height="100px"><br>
                                <h4><strong>Supp</strong></h4>
                            </a>
                        </li>                     
                        <li>
                            <a href="https://vlislab22.github.io/vlislab/">
                            <img src="./image/lab_logo.png" height="100px"><br>
                                <h4><strong>Vlislab</strong></h4>
                            </a>
                        </li>                       
                      
                    </ul>
                </div>
        </div>


        <!-- ##### Abstract #####-->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
			The ability to detect objects in all lighting (\ie, normal-, over-, and under-exposed) conditions is crucial for real-world applications, such as self-driving. Traditional RGB-based detectors often fail under such varying lighting conditions. 
		   	Therefore, recent works utilize novel event cameras to supplement or guide the RGB modality; however, these methods typically adopt asymmetric network structures that rely predominantly on the RGB modality, resulting in limited robustness for all-day detection.
			In this paper, we propose \textit{EOLO}, a novel object detection framework that achieves robust and efficient all-day detection by fusing both RGB and event modalities. Our EOLO framework is built based on a lightweight spiking neural network (SNN) to efficiently leverage the asynchronous property of events. Buttressed by it, we first introduce an Event Temporal Attention (ETA) module to learn the high temporal information from events while preserving crucial edge information.
			Secondly, as different modalities exhibit varying levels of importance under diverse lighting conditions, we propose a novel Symmetric RGB-Event Fusion (SREF) module to effectively fuse RGB-Event features without relying on a specific modality, thus ensuring a balanced and adaptive fusion for all-day detection.
			In addition, to compensate for the lack of paired RGB-Event datasets for all-day training and evaluation, we propose an event synthesis approach based on the randomized optical flow that allows for directly generating the event frame from a single exposure image.
We further build two new datasets, E-MSCOCO and E-VOC based on the popular benchmarks MSCOCO and PASCAL VOC.
Extensive experiments demonstrate that our EOLO outperforms the state-of-the-art detectors, \eg, RENet, by a substantial margin (+3.74% mAP_50) in all lighting conditions.
                </p>
            </div>
        </div>

 

        <!-- ##### Results #####-->

     <div class="row">     
        <div class="col-md-8 col-md-offset-2">
            <h3>
                Overall framework of our EOLO
            </h3>
            <img src="./image/main.png" class="img-responsive" alt="vis_res"  class="center" >
      	</div>
    </div>
<!-- ####      <div class="col-md-8 col-md-offset-2">
          <h3>
              Comparison on octree representations
          </h3>
          <p class="text-justify">
            DOT shows the more compact structure of DOT, 
            resulting in fewer ray intersections, explaining our significant rendering speed boost.

          </p>
		  <img src="./image/dot_cp.png" class="img-responsive" alt="vis_res" class="center"><br>
    </div>   
    <div class="col-md-8 col-md-offset-2">
        <h3>
            Comparison on visual quality and memory consumption
        </h3>
        <p class="text-justify">
            DOT provides more details in complex regions, such as sharper reflections on windows and more evident edges on fences. 

        </p>
        <img src="./image/dot_cp2.png" class="img-responsive" alt="vis_res" class="center"><br>
    </div>     
    </div>


		      
    	<div class="row">      
     <div class="col-md-8 col-md-offset-2">
          <h3>
              Demo 
          </h3>   
    </div>   
      
    <div class="col-md-8 col-md-offset-2">

            <video width="800"  controls >
                <source src="./video/dot.mp4" type="video/mp4">
              Your browser does not support HTML video.
            </video>   
    </div>          
      </div>  ####-->
   <!-- ##### BibTex #####-->
        <hr>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
 
                <div class="row align-items-center">
                    <div class="col py-3">
                        <pre class="border">             

</pre>
                    </div>
                </div>
              
    
          </div>
          
        </div>
    </div>
</body>
</html>
